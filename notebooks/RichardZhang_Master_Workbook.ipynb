{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f94847ba",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b541cae1",
   "metadata": {},
   "source": [
    "This is a master Jupyter notebook containing all works done by Richard Zhang (13627753) over the four weeks of the Assignment 1 group work.\n",
    "As subsequent weeks will use the packages and methods of previous weeks, the relevant package and method import is made only in the section corresponding to each week."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbfe71ba",
   "metadata": {},
   "source": [
    "# Week 1 works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79c1ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modules and methods used in this week\n",
    "from joblib import dump\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa39b9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data files\n",
    "df_raw_train = pd.read_csv('../data/raw/train.csv')\n",
    "df_raw_test = pd.read_csv('../data/raw/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a192913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare constants used for ML model trainings\n",
    "train_df_size = 0.8\n",
    "rand_state_ind = 42\n",
    "validation_df_size = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56e9bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training dataset checks\n",
    "df_raw_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473b30ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ca17b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check variable types\n",
    "df_raw_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9527ee35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check basic spreads of data of each variable\n",
    "df_raw_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38bb61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw_train.pop('Id')\n",
    "df_raw_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ec50db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Boxplots\n",
    "fig, ax = plt.subplots(1,5)\n",
    "for i in range(5):\n",
    "    ax[i].boxplot(df_raw_train.iloc[i])\n",
    "    ax[i].set_title(df_raw_train.columns[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d18279c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,5)\n",
    "for i in range(5,10):\n",
    "    ax[i-6].boxplot(df_raw_train.iloc[i])\n",
    "    ax[i-6].set_title(df_raw_train.columns[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3b6e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,5)\n",
    "for i in range(10,15):\n",
    "    ax[i-11].boxplot(df_raw_train.iloc[i])\n",
    "    ax[i-11].set_title(df_raw_train.columns[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0210ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,5)\n",
    "for i in range(15,20):\n",
    "    ax[i-16].boxplot(df_raw_train.iloc[i])\n",
    "    ax[i-16].set_title(df_raw_train.columns[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d1efdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histograms\n",
    "df_cleaned_train.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee6812a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test dataset checks\n",
    "df_raw_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee6361a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check basic spreads of data of each variable\n",
    "df_raw_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ff7ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check variable types\n",
    "df_raw_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b25f14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f29d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Boxplots\n",
    "fig, ax = plt.subplots(1,5)\n",
    "for i in range(5):\n",
    "    ax[i].boxplot(df_raw_test.iloc[i])\n",
    "    ax[i].set_title(df_raw_test.columns[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39658ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,5)\n",
    "for i in range(5,10):\n",
    "    ax[i-6].boxplot(df_raw_test.iloc[i])\n",
    "    ax[i-6].set_title(df_raw_test.columns[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d285b21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,5)\n",
    "for i in range(10,15):\n",
    "    ax[i-11].boxplot(df_raw_test.iloc[i])\n",
    "    ax[i-11].set_title(df_raw_test.columns[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad59620",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,4)\n",
    "for i in range(15,19):\n",
    "    ax[i-16].boxplot(df_raw_test.iloc[i])\n",
    "    ax[i-16].set_title(df_raw_test.columns[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eeb18a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process imported data\n",
    "df_cleaned_train = df_raw_train.copy()\n",
    "\n",
    "target = df_cleaned_train.pop('TARGET_5Yrs')\n",
    "IDlist_train = df_cleaned_train.pop('Id')\n",
    "df_col_names = df_cleaned_train.columns\n",
    "train_dataset_size = IDlist_train.size\n",
    "\n",
    "scaler = StandardScaler()\n",
    "array_cleaned_train = scaler.fit_transform(df_cleaned_train)\n",
    "df_cleaned2_train = pd.DataFrame(array_cleaned_train,columns=df_col_names)\n",
    "\n",
    "df_cleaned_test = df_raw_test.copy()\n",
    "IDlist_test = df_cleaned_test.pop('Id')\n",
    "array_cleaned_test = scaler.transform(df_cleaned_test) \n",
    "df_cleaned2_test = pd.DataFrame(array_cleaned_test,columns=df_col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43a655d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate second order variables, with full interaction variables\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "poly.feature_names_in_ = df_col_names\n",
    "array_clean_poly_train = poly.fit_transform(df_cleaned_train)\n",
    "polyFeatureNames = poly.get_feature_names_out()\n",
    "df_cleaned_poly_train = pd.DataFrame(array_clean_poly_train,columns=polyFeatureNames)\n",
    "\n",
    "array_clean_poly_test = poly.transform(df_cleaned_test)\n",
    "df_cleaned_poly_test = pd.DataFrame(array_clean_poly_test,columns=polyFeatureNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac52f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split first order dataset\n",
    "X_data, X_val, y_data, y_val = train_test_split(df_cleaned2_train, target, train_size=train_df_size, random_state=rand_state_ind, stratify=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8216bb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate a number of counts to check dataset\n",
    "y_train_pos_count = sum(target)\n",
    "y_train_neg_count = target.size - y_train_pos_count\n",
    "\n",
    "y_train_pos_count = sum(y_data)\n",
    "y_train_neg_count = y_data.size - y_train_pos_count\n",
    "\n",
    "y_val_pos_count = sum(y_val)\n",
    "y_val_neg_count = y_val.size - y_val_pos_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38688eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split polynomial dataset\n",
    "X_data_poly, X_val_poly, y_data_poly, y_val_poly = train_test_split(df_cleaned_poly_train, target, train_size=train_df_size, random_state=rand_state_ind, stratify=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb4d300",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logRegModel = LogisticRegression(penalty = 'l2')\n",
    "clf = logRegModel.fit(X_data,y_data)\n",
    "y_train_pred = clf.predict(X_data)\n",
    "y_val_pred = clf.predict(X_val)\n",
    "y_test_pred = clf.predict(df_cleaned2_test)\n",
    "\n",
    "roc_train = roc_auc_score(y_data, clf.predict_proba(X_data)[:,1])\n",
    "roc_val = roc_auc_score(y_val, clf.predict_proba(X_val)[:,1])\n",
    "\n",
    "y_train_pred_pos_count = sum(y_train_pred)\n",
    "y_train_pred_neg_count = y_data.size - y_train_pred_pos_count\n",
    "\n",
    "y_val_pred_pos_count = sum(y_val_pred)\n",
    "y_val_pred_neg_count = y_val.size - y_val_pred_pos_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd77e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stochastic gradient descent (SGD) model\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "SGDModel = SGDClassifier(loss='modified_huber')\n",
    "clf2 = SGDModel.fit(X_data,y_data)\n",
    "y_train_pred2 = clf2.predict(X_data)\n",
    "y_val_pred2 = clf2.predict(X_val)\n",
    "y_test_pred2 = clf2.predict(df_cleaned2_test)\n",
    "\n",
    "roc_train2 = roc_auc_score(y_data, clf2.predict_proba(X_data)[:,1])\n",
    "roc_val2 = roc_auc_score(y_val, clf2.predict_proba(X_val)[:,1])\n",
    "\n",
    "y_train_pred_pos_count2 = sum(y_train_pred2)\n",
    "y_train_pred_neg_count2 = y_data.size - y_train_pred_pos_count2\n",
    "\n",
    "y_val_pred_pos_count2 = sum(y_val_pred2)\n",
    "y_val_pred_neg_count2 = y_val.size - y_val_pred_pos_count2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9e3cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RFModel = RandomForestClassifier()\n",
    "clf3 = RFModel.fit(X_data,y_data)\n",
    "y_train_pred3 = clf3.predict(X_data)\n",
    "y_val_pred3 = clf3.predict(X_val)\n",
    "y_test_pred3 = clf3.predict(df_cleaned2_test)\n",
    "\n",
    "roc_train3 = roc_auc_score(y_data, clf3.predict_proba(X_data)[:,1])\n",
    "roc_val3 = roc_auc_score(y_val, clf3.predict_proba(X_val)[:,1])\n",
    "\n",
    "y_train_pred_pos_count3 = sum(y_train_pred3)\n",
    "y_train_pred_neg_count3 = y_data.size - y_train_pred_pos_count3\n",
    "\n",
    "y_val_pred_pos_count3 = sum(y_val_pred3)\n",
    "y_val_pred_neg_count3 = y_val.size - y_val_pred_pos_count3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef40370b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat Logistic Regression model for polynomial dataset\n",
    "clf_poly = logRegModel.fit(X_data_poly,y_data_poly)\n",
    "y_train_poly_pred = clf_poly.predict(X_data_poly)\n",
    "y_val_poly_pred = clf_poly.predict(X_val_poly)\n",
    "y_test_poly_pred = clf_poly.predict(df_cleaned_poly_test)\n",
    "\n",
    "roc_train_poly = roc_auc_score(y_data_poly, clf_poly.predict_proba(X_data_poly)[:,1])\n",
    "roc_val_poly = roc_auc_score(y_val_poly, clf_poly.predict_proba(X_val_poly)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8fd871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat SGD model for polynomial dataset\n",
    "clf_poly2 = SGDModel.fit(X_data_poly,y_data_poly)\n",
    "y_train_poly_pred2 = clf_poly2.predict(X_data_poly)\n",
    "y_val_poly_pred2 = clf_poly2.predict(X_val_poly)\n",
    "y_test_poly_pred2 = clf_poly2.predict(df_cleaned_poly_test)\n",
    "\n",
    "roc_train_poly2 = roc_auc_score(y_data_poly, clf_poly2.predict_proba(X_data_poly)[:,1])\n",
    "roc_val_poly2 = roc_auc_score(y_val_poly, clf_poly2.predict_proba(X_val_poly)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639c8675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat Random Forest model for polynomial dataset\n",
    "clf_poly3 = RFModel.fit(X_data_poly,y_data_poly)\n",
    "y_train_poly_pred3 = clf_poly3.predict(X_data_poly)\n",
    "y_val_poly_pred3 = clf_poly3.predict(X_val_poly)\n",
    "y_test_poly_pred3 = clf_poly3.predict(df_cleaned_poly_test)\n",
    "\n",
    "roc_train_poly3 = roc_auc_score(y_data_poly, clf_poly3.predict_proba(X_data_poly)[:,1])\n",
    "roc_val_poly3 = roc_auc_score(y_val_poly, clf_poly3.predict_proba(X_val_poly)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d68f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function of submission CSV file creation\n",
    "def BuildCSVforSubmission(IDlist,PredictionList):\n",
    "    iErrCode = 0\n",
    "    fFileName = 'submission.csv'\n",
    "    if (IDlist.size != 3799) or (PredictionList.size != 3799):\n",
    "        iErrCode = 1\n",
    "    if iErrCode == 0:\n",
    "        if not(isinstance(IDlist, pd.Series)):\n",
    "            list1 = pd.Series(IDlist)\n",
    "        else:\n",
    "            list1 = IDlist.copy()\n",
    "        if not(isinstance(PredictionList, pd.Series)):\n",
    "            list2 = pd.Series(PredictionList)\n",
    "        else:\n",
    "            list2 = IDlist.copy()\n",
    "        #list2.round(2)\n",
    "        #df_out = pd.DataFrame([list1,list2])\n",
    "        df_out = pd.DataFrame({'Id':list1,'TARGET_5Yrs':list2})\n",
    "        df_out.to_csv(path_or_buf = '../data/processed/'+fFileName,index=False)\n",
    "    return iErrCode\n",
    "\n",
    "roc_test = clf.predict_proba(df_cleaned2_test)[:,1]\n",
    "code = BuildCSVforSubmission(IDlist_test,roc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d777314a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement cross-validation for model training\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn import metrics\n",
    "\n",
    "scoring = ['roc_auc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196d910c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply cross-validation to all models\n",
    "logreg_scores = cross_validate(logRegModel, df_cleaned2_train, target, scoring=scoring, cv=20, return_train_score=True,return_estimator=True)\n",
    "SDG_scores = cross_validate(SGDModel, df_cleaned2_train, target, scoring=scoring, cv=20, return_train_score=True,return_estimator=True)\n",
    "randfor_scores = cross_validate(RFModel, df_cleaned2_train, target, scoring=scoring, cv=20, return_train_score=True,return_estimator=True)\n",
    "\n",
    "best_score = [np.max(logreg_scores.get('test_roc_auc')),np.max(SDG_scores.get('test_roc_auc')),np.max(randfor_scores.get('test_roc_auc'))]\n",
    "best_score_logreg = np.max(logreg_scores.get('test_roc_auc'))\n",
    "logreg_cv_models = logreg_scores.get('estimator')\n",
    "logreg_cv_scores = logreg_scores.get('test_roc_auc')\n",
    "logreg_cv_best_model = np.take(logreg_cv_models,(logreg_cv_scores==best_score_logreg))\n",
    "roc_test_cv = logreg_cv_best_model[0].predict_proba(df_cleaned2_test)[:,1]\n",
    "\n",
    "roc_test = clf.predict_proba(df_cleaned2_test)[:,1]\n",
    "code = BuildCSVforSubmission(IDlist_test,roc_test_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e12ef3",
   "metadata": {},
   "source": [
    "# Week 2 works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a9c0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement grid search with 10-fold cross-validation\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac1e348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression\n",
    "logRegModel = LogisticRegression(penalty = 'l2',max_iter=10000,random_state=42)\n",
    "models = ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "cRegStr = list([1.0,10])\n",
    "class_weight = [None,'balanced']\n",
    "scoring = 'roc_auc'\n",
    "param_grid = {'C':cRegStr,'class_weight':class_weight,'solver':models}\n",
    "cv = 10\n",
    "\n",
    "clf11 = GridSearchCV(estimator=logRegModel,param_grid=param_grid,cv=cv,scoring=scoring,return_train_score=True,verbose=3)\n",
    "clf11.fit(df_cleaned2_train, target)\n",
    "clf11.best_estimator_\n",
    "clf11.score(df_cleaned2_train, target)\n",
    "clf11.cv_results_.keys()\n",
    "test_grid_1 = clf11.predict_proba(df_cleaned2_test)[:,1]\n",
    "\n",
    "dump(clf11,  '../models/logreg_10cv_gridsearch_basic.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27c0c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic regression with a different grid\n",
    "logRegModel = LogisticRegression(penalty = 'l2',max_iter=10000,random_state=42)\n",
    "models = ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "cRegStr = np.logspace(start=-3,stop=3,num=7)\n",
    "class_weight = [None,'balanced']\n",
    "scoring = 'roc_auc'\n",
    "param_grid1a = {'C':cRegStr,'class_weight':class_weight,'solver':models}\n",
    "cv = 10\n",
    "\n",
    "clf11a = GridSearchCV(estimator=logRegModel,param_grid=param_grid1a,cv=cv,scoring=scoring,return_train_score=True,verbose=3)\n",
    "clf11a.fit(df_cleaned2_train, target)\n",
    "clf11a.best_estimator_\n",
    "clf11a.score(df_cleaned2_train, target)\n",
    "clf11a.cv_results_.keys()\n",
    "test_grid_1a = clf11a.predict_proba(df_cleaned2_test)[:,1]\n",
    "\n",
    "dump(clf11a,  '../models/logreg_10cv_gridsearch_basic2.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc73b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest\n",
    "RFModel = RandomForestClassifier(random_state=42)\n",
    "n_estimators = np.logspace(start=1, stop=round(math.log(train_dataset_size/2,2)),base=2,num=5).astype(int)\n",
    "max_depth = np.arange(start=2,stop=5)\n",
    "min_samples_split = np.logspace(start=1, stop=round(math.log(train_dataset_size/2),2),base=2,num=5).astype(int)\n",
    "param_grid2 = {'max_depth':max_depth,'n_estimators':n_estimators,'min_samples_split':min_samples_split}\n",
    "\n",
    "clf12 = GridSearchCV(estimator=RFModel,param_grid=param_grid2,cv=cv,scoring=scoring,return_train_score=True,verbose=3)\n",
    "clf12.fit(df_cleaned2_train, target)\n",
    "clf12.best_estimator_\n",
    "clf12.score(df_cleaned2_train, target)\n",
    "clf12.cv_results_.keys()\n",
    "test_grid_2 = clf12.predict_proba(df_cleaned2_test)[:,1]\n",
    "\n",
    "dump(clf12,  '../models/randforest_10cv_gridsearch_basic.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afe1c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SGD model\n",
    "SGDModel = SGDClassifier(max_iter=10000,random_state=42)\n",
    "loss_fn = ['hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron', 'squared_error', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive']\n",
    "alpha = np.linspace(start=-4, stop=3, num=8)\n",
    "l1_ratio = np.linspace(start=0, stop=1, num=6)\n",
    "learning_rate = ['constant', 'optimal', 'invscaling', 'adaptive']\n",
    "param_grid3 = {'loss':loss_fn,'alpha':alpha,'l1_ratio':l1_ratio,'learning_rate':learning_rate}\n",
    "\n",
    "clf13 = GridSearchCV(estimator=SGDModel,param_grid=param_grid3,cv=cv,scoring=scoring,return_train_score=True,verbose=3)\n",
    "clf13.fit(df_cleaned2_train, target)\n",
    "clf13.best_estimator_\n",
    "clf13.score(df_cleaned2_train, target)\n",
    "clf13.cv_results_.keys()\n",
    "test_grid_3 = clf13.predict_proba(df_cleaned2_test)[:,1]\n",
    "\n",
    "dump(clf13,  '../models/SDG_10cv_gridsearch_basic.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a51206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upsample the minority class\n",
    "from sklearn.utils import resample\n",
    "df_train_posclass = df_raw_train[df_raw_train['TARGET_5Yrs']==1]\n",
    "df_train_negclass = df_raw_train[df_raw_train['TARGET_5Yrs']==0]\n",
    "df_train_negclass_upsampled = resample(df_train_negclass, replace=True, n_samples=y_train_pos_count, random_state=42)\n",
    "\n",
    "df_cleaned3_train = pd.concat([df_train_posclass,df_train_negclass_upsampled])\n",
    "\n",
    "target = df_cleaned3_train.pop('TARGET_5Yrs')\n",
    "IDlist_train = df_cleaned3_train.pop('Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719680ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression on upsampled dataset with the same grid\n",
    "clf14 = GridSearchCV(estimator=logRegModel,param_grid=param_grid,cv=cv,scoring=scoring,return_train_score=True,verbose=3)\n",
    "clf14.fit(df_cleaned3_train, target)\n",
    "clf14.best_estimator_\n",
    "clf14.score(df_cleaned3_train, target)\n",
    "clf14.cv_results_.keys()\n",
    "test_grid_4 = clf11.predict_proba(df_cleaned2_test)[:,1]\n",
    "\n",
    "dump(clf14,  '../models/logreg_10cv_gridsearch_upsampled.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138c80b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest on upsampled dataset with the same grid\n",
    "clf15 = GridSearchCV(estimator=RFModel,param_grid=param_grid2,cv=cv,scoring=scoring,return_train_score=True,verbose=3)\n",
    "clf15.fit(df_cleaned3_train, target)\n",
    "clf15.best_estimator_\n",
    "clf15.score(df_cleaned3_train, target)\n",
    "clf15.cv_results_.keys()\n",
    "test_grid_5 = clf11.predict_proba(df_cleaned2_test)[:,1]\n",
    "\n",
    "dump(clf15,  '../models/randforest_10cv_gridsearch_upsampled.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6769282a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SGD on upsampled dataset with the same grid\n",
    "clf16 = GridSearchCV(estimator=SGDModel,param_grid=param_grid3,cv=cv,scoring=scoring,return_train_score=True,verbose=3)\n",
    "clf16.fit(df_cleaned3_train, target)\n",
    "clf16.best_estimator_\n",
    "clf16.score(df_cleaned3_train, target)\n",
    "clf16.cv_results_.keys()\n",
    "test_grid_6 = clf11.predict_proba(df_cleaned2_test)[:,1]\n",
    "\n",
    "dump(clf16,  '../models/SDG_10cv_gridsearch_upsampled.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd49f32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate XGBoost model\n",
    "import xgboost as xgb\n",
    "data_dmatrix_train = xgb.DMatrix(data=df_cleaned3_train,label=target)\n",
    "data_dmatrix_test = xgb.DMatrix(data=df_cleaned2_test)\n",
    "\n",
    "XGBModel = xgb.XGBClassifier(use_label_encoder=False, objective='binary:logistic', eval_metric='auc')\n",
    "\n",
    "X_data, X_val, y_data, y_val = train_test_split(df_cleaned3_train, target, train_size=train_df_size, random_state=rand_state_ind, stratify=target)\n",
    "\n",
    "clf6 = XGBModel.fit(X_data, y_data)\n",
    "y_pred = XGBModel.predict_proba(df_cleaned2_test)[:,1]\n",
    "roc_train_XGB = roc_auc_score(y_data, clf6.predict_proba(X_data)[:,1])\n",
    "roc_val_XGB = roc_auc_score(y_val, clf6.predict_proba(X_val)[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea48b0a",
   "metadata": {},
   "source": [
    "# Week 3 works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d540763b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redefine the first search grid for logistic regression\n",
    "logRegModel = LogisticRegression(penalty = 'l2',max_iter=10000,random_state=42)\n",
    "models = ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "cRegStr = np.logspace(start=-3,stop=0,num=21)\n",
    "class_weight = [None,'balanced']\n",
    "param_grid = {'C':cRegStr,'class_weight':class_weight,'solver':models}\n",
    "\n",
    "clf11 = GridSearchCV(estimator=logRegModel,param_grid=param_grid,cv=cv,scoring=scoring,return_train_score=True,verbose=3)\n",
    "clf11.fit(df_cleaned2_train, target)\n",
    "clf11.best_estimator_\n",
    "clf11.score(df_cleaned2_train, target)\n",
    "clf11.cv_results_.keys()\n",
    "test_grid_1 = clf11.predict_proba(df_cleaned2_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13aaf14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement randomised search using the same search grid\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "clf12 = RandomizedSearchCV(estimator=logRegModel,param_distributions=param_grid,n_iter = 30,cv=cv,scoring=scoring,return_train_score=True,verbose=3)\n",
    "clf12.fit(df_cleaned2_train, target)\n",
    "clf12.score(df_cleaned2_train, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e0e7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a search grid for XBBoost\n",
    "n_estimators = np.logspace(start=1, stop=round(math.log(train_dataset_size/2,2)),base=2,num=5).astype(int)\n",
    "max_depth = np.arange(start=2,stop=5)\n",
    "min_child_weight = np.logspace(start=1, stop=round(math.log(train_dataset_size/2),2),base=2,num=5).astype(int)\n",
    "learning_rate = np.logspace(start=-3,stop=-0.1,num=7)\n",
    "param_grid2 = {'max_depth':max_depth,'n_estimators':n_estimators,'min_child_weight':min_child_weight,'learning_rate':learning_rate}\n",
    "\n",
    "clf13 = GridSearchCV(estimator=XGBModel,param_grid=param_grid2,cv=cv,scoring=scoring,return_train_score=True,verbose=3)\n",
    "clf13.fit(df_cleaned2_train, target)\n",
    "clf13.score(df_cleaned2_train, target)\n",
    "\n",
    "dump(clf13,  '../models/XGB_10cv_gridsearch_basic.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae04cb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a second search grid for XBBoost\n",
    "n_estimators = np.logspace(start=1, stop=round(math.log(train_dataset_size/4,2)),base=2,num=5).astype(int)\n",
    "max_depth = np.arange(start=2,stop=5)\n",
    "min_child_weight = np.logspace(start=1, stop=round(math.log(train_dataset_size/4),2),base=2,num=5).astype(int)\n",
    "learning_rate = np.logspace(start=-3,stop=-0.1,num=4)\n",
    "param_grid3 = {'max_depth':max_depth,'n_estimators':n_estimators,'min_child_weight':min_child_weight,'learning_rate':learning_rate}\n",
    "\n",
    "clf14 = GridSearchCV(estimator=XGBModel,param_grid=param_grid3,cv=cv,scoring=scoring,return_train_score=True,verbose=3)\n",
    "clf14.fit(df_cleaned3_train, target_upsampled)\n",
    "clf14.score(df_cleaned3_train, target_upsampled)\n",
    "\n",
    "dump(clf14,  '../models/XGB_10cv_gridsearch_upsampled.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af05c4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a second XGBoost search grid with more hyperparameters\n",
    "XGBModel2 = xgb.XGBClassifier(use_label_encoder=False, objective='binary:logistic', eval_metric='auc',\n",
    "                             sampling_method='gradient_based')\n",
    "\n",
    "n_estimators = np.logspace(start=round(math.log(train_dataset_size/20,2)), stop=round(math.log(train_dataset_size/4,2)),base=2,num=5).astype(int)\n",
    "max_depth = np.arange(start=2,stop=5)\n",
    "min_child_weight = np.logspace(start=round(math.log(train_dataset_size/20,2)), stop=round(math.log(train_dataset_size/4),2),base=2,num=5).astype(int)\n",
    "learning_rate = np.logspace(start=-2,stop=0,num=5)\n",
    "lambda_reg = np.logspace(start=0,stop=2,num=3)\n",
    "alpha_reg = np.logspace(start=0,stop=2,num=3)\n",
    "param_grid4 = {'max_depth':max_depth,'n_estimators':n_estimators,'min_child_weight':min_child_weight,\n",
    "               'learning_rate':learning_rate,'lambda':lambda_reg,'alpha':alpha_reg}\n",
    "\n",
    "clf17 = GridSearchCV(estimator=XGBModel2,param_grid=param_grid4,cv=cv,scoring=scoring,return_train_score=True,verbose=3)\n",
    "clf17.fit(df_cleaned3_train, target_upsampled)\n",
    "clf17.score(df_cleaned3_train, target_upsampled)\n",
    "\n",
    "dump(clf17,  '../models/XGB_10cv_gridsearch_biggergrid_upsampled.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a35cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the second search grid for randomised search\n",
    "clf18 = RandomizedSearchCV(estimator=XGBModel2,param_distributions=param_grid4,n_iter = 100,cv=cv,scoring=scoring,return_train_score=True,verbose=3)\n",
    "clf18.fit(df_cleaned3_train, target_upsampled)\n",
    "clf18.score(df_cleaned3_train, target_upsampled)\n",
    "clf18.best_estimator_\n",
    "\n",
    "dump(clf18,  '../models/XGB_10cv_randomsearch_biggergrid_upsampled.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f8df96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a third XGBoost search grid with more hyperparameters\n",
    "XGBModel3 = xgb.XGBClassifier(use_label_encoder=False, objective='binary:logistic', eval_metric='auc',\n",
    "                             sampling_method='gradient_based',max_depth=4)\n",
    "\n",
    "n_estimators = np.logspace(start=round(math.log(train_dataset_size/20,2)), stop=round(math.log(train_dataset_size/4,2)),base=2,num=5).astype(int)\n",
    "min_child_weight = np.logspace(start=round(math.log(train_dataset_size/20,2)), stop=round(math.log(train_dataset_size/4),2),base=2,num=5).astype(int)\n",
    "learning_rate = np.logspace(start=-2,stop=0,num=201)\n",
    "param_grid5 = {'n_estimators':n_estimators,'min_child_weight':min_child_weight,\n",
    "               'learning_rate':learning_rate}\n",
    "\n",
    "clf19 = RandomizedSearchCV(estimator=XGBModel3,param_distributions=param_grid5,n_iter = 100,cv=cv,scoring=scoring,return_train_score=True,verbose=3)\n",
    "clf19.fit(df_cleaned3_train, target_upsampled)\n",
    "clf19.score(df_cleaned3_train, target_upsampled)\n",
    "clf19.best_estimator_\n",
    "\n",
    "dump(clf19,  '../models/XGB_10cv_randomsearch_biggergrid_upsampled2.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a91a62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a fourth XGBoost search grid with more hyperparameters\n",
    "n_estimators = np.logspace(start=round(math.log(train_dataset_size/20,2)), stop=round(math.log(train_dataset_size/4,2)),base=2,num=5).astype(int)\n",
    "min_child_weight = np.logspace(start=round(math.log(train_dataset_size/20,2)), stop=round(math.log(train_dataset_size/4),2),base=2,num=5).astype(int)\n",
    "learning_rate = np.linspace(start=0.5,stop=1.0,num=201)\n",
    "param_grid6 = {'n_estimators':n_estimators,'min_child_weight':min_child_weight,\n",
    "               'learning_rate':learning_rate}\n",
    "\n",
    "clf21 = RandomizedSearchCV(estimator=XGBModel3,param_distributions=param_grid6,n_iter = 100,cv=cv,scoring=scoring,return_train_score=True,verbose=3)\n",
    "clf21.fit(df_cleaned4_train, target_upsampled)\n",
    "clf21.score(df_cleaned4_train, target_upsampled)\n",
    "clf21.best_estimator_\n",
    "\n",
    "dump(clf21,  '../models/XGB_10cv_randomsearch_biggergrid_upsampled4.joblib')\n",
    "\n",
    "roc_test = clf21.best_estimator_.predict_proba(df_cleaned4_test)[:,1]\n",
    "code = BuildCSVforSubmission(IDlist_test,roc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94a567a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retry logistic regression with a different grid\n",
    "logRegModel = LogisticRegression(penalty = 'l2',max_iter=10000,random_state=42,class_weight='balanced',solver='saga')\n",
    "cRegStr = np.logspace(start=-3,stop=2,num=61)\n",
    "param_grid = {'C':cRegStr}\n",
    "\n",
    "clf22 = GridSearchCV(estimator=logRegModel,param_grid=param_grid,cv=cv,scoring=scoring,return_train_score=True,verbose=3)\n",
    "clf22.fit(df_cleaned2_train, target)\n",
    "clf22.best_estimator_\n",
    "clf22.score(df_cleaned2_train, target)\n",
    "clf22.cv_results_.keys()\n",
    "\n",
    "dump(clf22,  '../models/logreg_10cv_gridsearch_Cvaluesonly.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf56c882",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retry logistic regression with a different grid, based on the best model of the above grid\n",
    "cRegStr = np.logspace(start=-3,stop=0,num=61)\n",
    "param_grid = {'C':cRegStr}\n",
    "\n",
    "clf23 = GridSearchCV(estimator=logRegModel,param_grid=param_grid,cv=cv,scoring=scoring,return_train_score=True,verbose=3)\n",
    "clf23.fit(df_cleaned2_train, target)\n",
    "clf23.best_estimator_\n",
    "clf23.score(df_cleaned2_train, target)\n",
    "clf23.cv_results_.keys()\n",
    "\n",
    "dump(clf23,  '../models/logreg_10cv_gridsearch_Cvaluesonly2.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88083d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retry logistic regression with a different grid, based on the best model of the above grid\n",
    "cRegStr = np.logspace(start=-3,stop=0,num=121)\n",
    "param_grid = {'C':cRegStr}\n",
    "\n",
    "clf24 = GridSearchCV(estimator=logRegModel,param_grid=param_grid,cv=cv,scoring=scoring,return_train_score=True,verbose=3)\n",
    "clf24.fit(df_cleaned2_train, target)\n",
    "clf24.best_estimator_\n",
    "clf24.score(df_cleaned2_train, target)\n",
    "clf24.cv_results_.keys()\n",
    "\n",
    "dump(clf24,  '../models/logreg_10cv_gridsearch_Cvaluesonly3.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8495d83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retry logistic regression with a second different grid\n",
    "logRegModel = LogisticRegression(penalty = 'elasticnet',max_iter=10000,random_state=42,class_weight='balanced',solver='saga')\n",
    "l1ratio = np.linspace(start=0,stop=1,num=5)\n",
    "cRegStr = np.logspace(start=-3,stop=-0.5,num=6)\n",
    "param_grid = {'C':cRegStr,'l1_ratio':l1ratio}\n",
    "\n",
    "clf25 = GridSearchCV(estimator=logRegModel,param_grid=param_grid,cv=cv,scoring=scoring,return_train_score=True,verbose=3)\n",
    "clf25.fit(df_cleaned2_train, target)\n",
    "clf25.best_estimator_\n",
    "clf25.score(df_cleaned2_train, target)\n",
    "clf25.cv_results_.keys()\n",
    "\n",
    "dump(clf25,  '../models/logreg_10cv_gridsearch_Cvaluesonly4.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b101e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retry logistic regression with a second different grid, based on the best model of the above grid\n",
    "logRegModel = LogisticRegression(penalty = 'elasticnet',max_iter=10000,random_state=42,solver='saga')\n",
    "\n",
    "clf26 = GridSearchCV(estimator=logRegModel,param_grid=param_grid,cv=cv,scoring=scoring,return_train_score=True,verbose=3)\n",
    "clf26.fit(df_cleaned3_train, target_upsampled)\n",
    "clf26.best_estimator_\n",
    "clf26.score(df_cleaned3_train, target_upsampled)\n",
    "clf26.cv_results_.keys()\n",
    "\n",
    "dump(clf26,  '../models/logreg_10cv_gridsearch_Cvaluesonly_upsampled1.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22dfcfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retry logistic regression with a third different grid, based on the best model of the above grid\n",
    "logRegModel = LogisticRegression(l1_ratio=1.0,penalty = 'elasticnet',max_iter=10000,random_state=42,class_weight='balanced',solver='saga')\n",
    "cRegStr = np.linspace(start=0.2,stop=.4,num=21)\n",
    "param_grid8 = {'C':cRegStr}\n",
    "\n",
    "clf27 = GridSearchCV(estimator=logRegModel,param_grid=param_grid8,cv=cv,scoring=scoring,return_train_score=True,verbose=3)\n",
    "clf27.fit(df_cleaned3_train, target_upsampled)\n",
    "clf27.best_estimator_\n",
    "clf27.score(df_cleaned3_train, target_upsampled)\n",
    "clf27.cv_results_.keys()\n",
    "\n",
    "dump(clf27,  '../models/logreg_10cv_gridsearch_Cvaluesonly_upsampled2.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7cf14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retry logistic regression with a fourth different grid\n",
    "logRegModel = LogisticRegression(l1_ratio=1.0,penalty = 'elasticnet',max_iter=10000,random_state=42,class_weight='balanced',solver='saga')\n",
    "cRegStr = np.linspace(start=0.4,stop=.6,num=21)\n",
    "param_grid9 = {'C':cRegStr}\n",
    "\n",
    "clf28 = GridSearchCV(estimator=logRegModel,param_grid=param_grid9,cv=cv,scoring=scoring,return_train_score=True,verbose=3)\n",
    "clf28.fit(df_cleaned3_train, target_upsampled)\n",
    "clf28.best_estimator_\n",
    "clf28.score(df_cleaned3_train, target_upsampled)\n",
    "clf28.cv_results_.keys()\n",
    "\n",
    "dump(clf28,  '../models/logreg_10cv_gridsearch_Cvaluesonly_upsampled3.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72825c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dataset with three variables dropped\n",
    "df_cleaned5_train = df_cleaned3_train.copy()\n",
    "df_cleaned5_train.pop('FG%')\n",
    "df_cleaned5_train.pop('3P%')\n",
    "df_cleaned5_train.pop('FT%')\n",
    "df_cleaned5_test = df_cleaned2_test.copy()\n",
    "df_cleaned5_test.pop('FG%')\n",
    "df_cleaned5_test.pop('3P%')\n",
    "df_cleaned5_test.pop('FT%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8d2895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a search grid for model training with reduced variable dataset\n",
    "logRegModel = LogisticRegression(penalty = 'elasticnet',max_iter=10000,random_state=42,class_weight='balanced',solver='saga')\n",
    "l1ratio = np.linspace(start=0,stop=1,num=5)\n",
    "cRegStr = np.logspace(start=-3,stop=2,num=11)\n",
    "param_grid6 = {'C':cRegStr,'l1_ratio':l1ratio}\n",
    "\n",
    "clf31 = GridSearchCV(estimator=logRegModel,param_grid=param_grid6,cv=cv,scoring=scoring,return_train_score=True,verbose=3)\n",
    "clf31.fit(df_cleaned5_train, target_upsampled)\n",
    "clf31.best_estimator_\n",
    "clf31.score(df_cleaned5_train, target_upsampled)\n",
    "\n",
    "dump(clf31,  '../models/logreg_10cv_gridsearch_Cvaluesonly1_vardrop.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efa8fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a second search grid for model training with reduced variable dataset based on the first grid\n",
    "logRegModel = LogisticRegression(l1_ratio=1.0,penalty = 'elasticnet',max_iter=10000,random_state=42,class_weight='balanced',solver='saga')\n",
    "cRegStr = np.linspace(start=0.4,stop=.6,num=21)\n",
    "param_grid9 = {'C':cRegStr}\n",
    "\n",
    "clf32 = GridSearchCV(estimator=logRegModel,param_grid=param_grid9,cv=cv,scoring=scoring,return_train_score=True,verbose=3)\n",
    "clf32.fit(df_cleaned3_train, target_upsampled)\n",
    "clf32.best_estimator_\n",
    "clf32.score(df_cleaned3_train, target_upsampled)\n",
    "clf32.cv_results_.keys()\n",
    "\n",
    "dump(clf32,  '../models/logreg_10cv_gridsearch_Cvaluesonly_upsampled4.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152b3ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a third search grid for model training with reduced variable dataset based on the second grid\n",
    "logRegModel = LogisticRegression(l1_ratio=1.0,penalty = 'elasticnet',max_iter=10000,random_state=42,class_weight='balanced',solver='saga')\n",
    "cRegStr = np.linspace(start=0.55,stop=.58,num=21)\n",
    "param_grid9 = {'C':cRegStr}\n",
    "\n",
    "clf33 = GridSearchCV(estimator=logRegModel,param_grid=param_grid9,cv=cv,scoring=scoring,return_train_score=True,verbose=3)\n",
    "clf33.fit(df_cleaned3_train, target_upsampled)\n",
    "clf33.best_estimator_\n",
    "clf33.score(df_cleaned3_train, target_upsampled)\n",
    "clf33.cv_results_.keys()\n",
    "\n",
    "dump(clf33,  '../models/logreg_10cv_gridsearch_Cvaluesonly_upsampled5.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96abc1fd",
   "metadata": {},
   "source": [
    "# Week 4 works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50834311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable selection set 2\n",
    "selected_features2 = ['GP','MIN','PTS','FGA','FGM','FG%','REB','FTA','OREB']\n",
    "\n",
    "#original set\n",
    "df_cleaned4_train = df_cleaned2_train.copy()\n",
    "df_cleaned4_train = df_cleaned4_train.loc[:,selected_features2]\n",
    "df_cleaned4_test = df_cleaned2_train.copy()\n",
    "df_cleaned4_test = df_cleaned4_test.loc[:,selected_features2]\n",
    "\n",
    "#Upsampled set\n",
    "df_cleaned5_train = df_cleaned3_train.copy()\n",
    "df_cleaned5_train = df_cleaned5_train.loc[:,selected_features2]\n",
    "df_cleaned5_test = df_cleaned3_train.copy()\n",
    "df_cleaned5_test = df_cleaned5_test.loc[:,selected_features2]\n",
    "\n",
    "#Variable selection set 3\n",
    "selected_features1 = ['GP','FGM','3P Made','OREB','DREB']\n",
    "\n",
    "#original set\n",
    "df_cleaned6_train = df_cleaned2_train.copy()\n",
    "df_cleaned6_train = df_cleaned6_train.loc[:,selected_features1]\n",
    "df_cleaned6_test = df_cleaned2_train.copy()\n",
    "df_cleaned6_test = df_cleaned6_test.loc[:,selected_features1]\n",
    "\n",
    "#Upsampled set\n",
    "df_cleaned7_train = df_cleaned3_train.copy()\n",
    "df_cleaned7_train = df_cleaned7_train.loc[:,selected_features1]\n",
    "df_cleaned7_test = df_cleaned3_train.copy()\n",
    "df_cleaned7_test = df_cleaned7_test.loc[:,selected_features1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fa6999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search on logistic regression using original dataset\n",
    "logRegModel = LogisticRegression(l1_ratio=1.0,penalty = 'elasticnet',max_iter=10000,random_state=42,class_weight='balanced',solver='saga')\n",
    "cRegStr = np.linspace(start=0,stop=1,num=11)\n",
    "param_grid11 = {'C':cRegStr}\n",
    "\n",
    "clf51 = GridSearchCV(estimator=logRegModel,param_grid=param_grid11,cv=cv,scoring=scoring,return_train_score=True,verbose=3)\n",
    "clf51.fit(df_cleaned2_train, target)\n",
    "clf51.best_estimator_\n",
    "clf51.score(df_cleaned2_train, target)\n",
    "clf51.cv_results_.keys()\n",
    "\n",
    "dump(clf51,  '../models/logreg_10cv_gridsearch_Cvaluesonly_vardropcompare1.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024fddd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search on logistic regression using original dataset and upsampled\n",
    "clf52 = GridSearchCV(estimator=logRegModel,param_grid=param_grid11,cv=cv,scoring=scoring,return_train_score=True,verbose=3)\n",
    "clf52.fit(df_cleaned3_train, target_upsampled)\n",
    "clf52.best_estimator_\n",
    "clf52.score(df_cleaned3_train, target_upsampled)\n",
    "clf52.cv_results_.keys()\n",
    "\n",
    "dump(clf52,  '../models/logreg_10cv_gridsearch_Cvaluesonly_vardropcompare2.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bdf1937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search on logistic regression using Variable selection set 2\n",
    "clf53 = GridSearchCV(estimator=logRegModel,param_grid=param_grid11,cv=cv,scoring=scoring,return_train_score=True,verbose=3)\n",
    "clf53.fit(df_cleaned4_train, target)\n",
    "clf53.best_estimator_\n",
    "clf53.score(df_cleaned4_train, target)\n",
    "clf53.cv_results_.keys()\n",
    "\n",
    "dump(clf53,  '../models/logreg_10cv_gridsearch_Cvaluesonly_vardropcompare3.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7905a2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search on logistic regression using Variable selection set 2 with upsampled\n",
    "clf54 = GridSearchCV(estimator=logRegModel,param_grid=param_grid11,cv=cv,scoring=scoring,return_train_score=True,verbose=3)\n",
    "clf54.fit(df_cleaned5_train, target_upsampled)\n",
    "clf54.best_estimator_\n",
    "clf54.score(df_cleaned5_train, target_upsampled)\n",
    "clf54.cv_results_.keys()\n",
    "\n",
    "dump(clf54,  '../models/logreg_10cv_gridsearch_Cvaluesonly_vardropcompare4.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0815c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search on random forest using Variable selection set 2\n",
    "RFModel = RandomForestClassifier(random_state=42)\n",
    "max_depth = np.arange(start=2,stop=7)\n",
    "n_estimators = np.linspace(start=75, stop=95,num=6).astype(int)\n",
    "min_samples_split = np.linspace(start=25, stop=45,num=6).astype(int)\n",
    "param_grid16 = {'max_depth':max_depth,'n_estimators':n_estimators,'min_samples_split':min_samples_split}\n",
    "\n",
    "clf61 = GridSearchCV(estimator=RFModel,param_grid=param_grid16,cv=cv,scoring=scoring,return_train_score=True,verbose=3)\n",
    "clf61.fit(df_cleaned4_train, target)\n",
    "clf61.best_estimator_\n",
    "clf61.score(df_cleaned4_train, target)\n",
    "clf61.cv_results_.keys()\n",
    "\n",
    "dump(clf61,  '../models/randforest_10cv_gridsearch_vardrop6.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25edf216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search on random forest using Variable selection set 3\n",
    "RFModel = RandomForestClassifier(random_state=42)\n",
    "max_depth = np.arange(start=2,stop=7)\n",
    "n_estimators = np.linspace(start=75, stop=95,num=6).astype(int)\n",
    "min_samples_split = np.linspace(start=25, stop=45,num=6).astype(int)\n",
    "param_grid18 = {'max_depth':max_depth,'n_estimators':n_estimators,'min_samples_split':min_samples_split}\n",
    "\n",
    "clf62 = GridSearchCV(estimator=RFModel,param_grid=param_grid18,cv=cv,scoring=scoring,return_train_score=True,verbose=3)\n",
    "clf62.fit(df_cleaned6_train, target)\n",
    "clf62.best_estimator_\n",
    "clf62.score(df_cleaned6_train, target)\n",
    "clf62.cv_results_.keys()\n",
    "\n",
    "dump(clf62,  '../models/randforest_10cv_gridsearch_vardrop7.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89a5f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search on random forest using Variable selection set 3, using a new grid\n",
    "RFModel = RandomForestClassifier(random_state=42)\n",
    "max_depth = np.arange(start=2,stop=7)\n",
    "n_estimators = np.linspace(start=95, stop=125,num=6).astype(int)\n",
    "min_samples_split = np.linspace(start=25, stop=45,num=6).astype(int)\n",
    "param_grid19 = {'max_depth':max_depth,'n_estimators':n_estimators,'min_samples_split':min_samples_split}\n",
    "\n",
    "clf63 = GridSearchCV(estimator=RFModel,param_grid=param_grid19,cv=cv,scoring=scoring,return_train_score=True,verbose=3)\n",
    "clf63.fit(df_cleaned6_train, target)\n",
    "clf63.best_estimator_\n",
    "clf63.score(df_cleaned6_train, target)\n",
    "clf63.cv_results_.keys()\n",
    "\n",
    "dump(clf63,  '../models/randforest_10cv_gridsearch_vardrop8.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
