{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7946dd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump,load\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_raw_train = pd.read_csv('../data/raw/train.csv')\n",
    "df_raw_test = pd.read_csv('../data/raw/test.csv')\n",
    "\n",
    "train_df_size = 0.8\n",
    "rand_state_ind = 42\n",
    "validation_df_size = 0.2\n",
    "scoring = 'roc_auc'\n",
    "cv = 10\n",
    "\n",
    "df_cleaned_train = df_raw_train.copy()\n",
    "\n",
    "target = df_cleaned_train.pop('TARGET_5Yrs')\n",
    "IDlist_train = df_cleaned_train.pop('Id')\n",
    "df_col_names = df_cleaned_train.columns\n",
    "train_dataset_size = IDlist_train.size\n",
    "\n",
    "df_cleaned_train[df_cleaned_train<0] = 0\n",
    "\n",
    "scaler = StandardScaler()\n",
    "array_cleaned_train = scaler.fit_transform(df_cleaned_train)\n",
    "df_cleaned2_train = pd.DataFrame(array_cleaned_train,columns=df_col_names)\n",
    "#df_cleaned2_train.insert(loc=0,column='Id',value=IDlist_train)\n",
    "#df_cleaned2_train.set_index(keys='Id',drop=False,verify_integrity=True)\n",
    "\n",
    "df_cleaned_test = df_raw_test.copy()\n",
    "IDlist_test = df_cleaned_test.pop('Id')\n",
    "df_cleaned_test[df_cleaned_test<0] = 0\n",
    "\n",
    "array_cleaned_test = scaler.transform(df_cleaned_test) \n",
    "df_cleaned2_test = pd.DataFrame(array_cleaned_test,columns=df_col_names)\n",
    "\n",
    "y_train_pos_count = sum(target)\n",
    "y_train_neg_count = target.size - y_train_pos_count\n",
    "\n",
    "def BuildCSVforSubmission(IDlist,PredictionList):\n",
    "    iErrCode = 0\n",
    "    fFileName = 'submission.csv'\n",
    "    if (IDlist.size != 3799) or (PredictionList.size != 3799):\n",
    "        iErrCode = 1\n",
    "    if iErrCode == 0:\n",
    "        if not(isinstance(IDlist, pd.Series)):\n",
    "            list1 = pd.Series(IDlist)\n",
    "        else:\n",
    "            list1 = IDlist.copy()\n",
    "        if not(isinstance(PredictionList, pd.Series)):\n",
    "            list2 = pd.Series(PredictionList)\n",
    "        else:\n",
    "            list2 = IDlist.copy()\n",
    "        #list2.round(2)\n",
    "        #df_out = pd.DataFrame([list1,list2])\n",
    "        df_out = pd.DataFrame({'Id':list1,'TARGET_5Yrs':list2})\n",
    "        df_out.to_csv(path_or_buf = '../data/processed/'+fFileName,index=False)\n",
    "    return iErrCode\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "logRegModel = LogisticRegression(penalty = 'l2',max_iter=10000,random_state=42)\n",
    "models = ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "cRegStr = np.logspace(start=-3,stop=0,num=21)\n",
    "class_weight = [None,'balanced']\n",
    "param_grid = {'C':cRegStr,'class_weight':class_weight,'solver':models}\n",
    "#param_grid = {'C':cRegStr,'solver':models}\n",
    "\n",
    "\n",
    "clf11 = GridSearchCV(estimator=logRegModel,param_grid=param_grid,cv=cv,scoring=scoring,return_train_score=True,verbose=3)\n",
    "clf11.fit(df_cleaned2_train, target)\n",
    "clf11.best_estimator_\n",
    "clf11.score(df_cleaned2_train, target)\n",
    "clf11.cv_results_.keys()\n",
    "test_grid_1 = clf11.predict_proba(df_cleaned2_test)[:,1]\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "clf12 = RandomizedSearchCV(estimator=logRegModel,param_distributions=param_grid,n_iter = 30,cv=cv,scoring=scoring,return_train_score=True,verbose=3)\n",
    "clf12.fit(df_cleaned2_train, target)\n",
    "clf12.score(df_cleaned2_train, target)\n",
    "\n",
    "import xgboost as xgb\n",
    "data_dmatrix_train = xgb.DMatrix(data=df_cleaned2_train,label=target)\n",
    "data_dmatrix_test = xgb.DMatrix(data=df_cleaned2_test)\n",
    "\n",
    "XGBModel = xgb.XGBClassifier(use_label_encoder=False, objective='binary:logistic', eval_metric='auc')\n",
    "\n",
    "#X_data, X_val, y_data, y_val = train_test_split(df_cleaned3_train, target, train_size=train_df_size, random_state=rand_state_ind, stratify=target)\n",
    "\n",
    "clf6 = XGBModel.fit(X_data, y_data)\n",
    "y_pred = XGBModel.predict_proba(df_cleaned2_test)[:,1]\n",
    "roc_train_XGB = roc_auc_score(y_data, clf6.predict_proba(X_data)[:,1])\n",
    "roc_val_XGB = roc_auc_score(y_val, clf6.predict_proba(X_val)[:,1])\n",
    "\n",
    "n_estimators = np.logspace(start=1, stop=round(math.log(train_dataset_size/2,2)),base=2,num=5).astype(int)\n",
    "max_depth = np.arange(start=2,stop=5)\n",
    "min_child_weight = np.logspace(start=1, stop=round(math.log(train_dataset_size/2),2),base=2,num=5).astype(int)\n",
    "learning_rate = np.logspace(start=-3,stop=-0.1,num=7)\n",
    "param_grid2 = {'max_depth':max_depth,'n_estimators':n_estimators,'min_child_weight':min_child_weight,'learning_rate':learning_rate}\n",
    "\n",
    "clf13 = GridSearchCV(estimator=XGBModel,param_grid=param_grid2,cv=cv,scoring=scoring,return_train_score=True,verbose=3)\n",
    "clf13.fit(df_cleaned2_train, target)\n",
    "clf13.score(df_cleaned2_train, target)\n",
    "\n",
    "dump(clf13,  '../models/XGB_10cv_gridsearch_basic.joblib')\n",
    "\n",
    "clf_X11 = load('../models/XGB_10cv_gridsearch_basic.joblib')\n",
    "\n",
    "roc_test = clf_X11.predict_proba(df_cleaned2_test)[:,1]\n",
    "code = BuildCSVforSubmission(IDlist_test,roc_test)\n",
    "\n",
    "from sklearn.utils import resample\n",
    "df_train_posclass = df_raw_train[df_raw_train['TARGET_5Yrs']==1]\n",
    "df_train_negclass = df_raw_train[df_raw_train['TARGET_5Yrs']==0]\n",
    "df_train_negclass_upsampled = resample(df_train_negclass, replace=True, n_samples=y_train_pos_count, random_state=42)\n",
    "\n",
    "df_cleaned3_train = pd.concat([df_train_posclass,df_train_negclass_upsampled])\n",
    "\n",
    "target_upsampled = df_cleaned3_train.pop('TARGET_5Yrs')\n",
    "IDlist_train_upsampled = df_cleaned3_train.pop('Id')\n",
    "\n",
    "n_estimators = np.logspace(start=1, stop=round(math.log(train_dataset_size/4,2)),base=2,num=5).astype(int)\n",
    "max_depth = np.arange(start=2,stop=5)\n",
    "min_child_weight = np.logspace(start=1, stop=round(math.log(train_dataset_size/4),2),base=2,num=5).astype(int)\n",
    "learning_rate = np.logspace(start=-3,stop=-0.1,num=4)\n",
    "param_grid3 = {'max_depth':max_depth,'n_estimators':n_estimators,'min_child_weight':min_child_weight,'learning_rate':learning_rate}\n",
    "\n",
    "clf14 = GridSearchCV(estimator=XGBModel,param_grid=param_grid3,cv=cv,scoring=scoring,return_train_score=True,verbose=3)\n",
    "clf14.fit(df_cleaned3_train, target_upsampled)\n",
    "clf14.score(df_cleaned3_train, target_upsampled)\n",
    "\n",
    "dump(clf14,  '../models/XGB_10cv_gridsearch_upsampled.joblib')\n",
    "\n",
    "# StandarsScale no negative reset\n",
    "clf16 = GridSearchCV(estimator=XGBModel,param_grid=param_grid3,cv=cv,scoring=scoring,return_train_score=True,verbose=3)\n",
    "clf16.fit(df_cleaned3_train, target_upsampled)\n",
    "clf16.score(df_cleaned3_train, target_upsampled)\n",
    "clf16.best_estimator_\n",
    "\n",
    "dump(clf16,  '../models/XGB_10cv_gridsearch_upsampled_includenegs.joblib')\n",
    "\n",
    "\n",
    "df_cleaned4_train = df_raw_train.copy()\n",
    "target4 = df_cleaned4_train.pop('TARGET_5Yrs')\n",
    "IDlist_train4 = df_cleaned4_train.pop('Id')\n",
    "\n",
    "df_cleaned_test4 = df_raw_test.copy()\n",
    "IDlist_test4 = df_cleaned_test4.pop('Id')\n",
    "\n",
    "clf15 = GridSearchCV(estimator=XGBModel,param_grid=param_grid3,cv=cv,scoring=scoring,return_train_score=True,verbose=3)\n",
    "clf15.fit(df_cleaned4_train, target4)\n",
    "clf15.score(df_cleaned4_train, target4)\n",
    "\n",
    "dump(clf15,  '../models/XGB_10cv_gridsearch_unscaled.joblib')\n",
    "\n",
    "\n",
    "# MOre hyperparameters\n",
    "XGBModel2 = xgb.XGBClassifier(use_label_encoder=False, objective='binary:logistic', eval_metric='auc',\n",
    "                             sampling_method='gradient_based')\n",
    "\n",
    "n_estimators = np.logspace(start=round(math.log(train_dataset_size/20,2)), stop=round(math.log(train_dataset_size/4,2)),base=2,num=5).astype(int)\n",
    "max_depth = np.arange(start=2,stop=5)\n",
    "min_child_weight = np.logspace(start=round(math.log(train_dataset_size/20,2)), stop=round(math.log(train_dataset_size/4),2),base=2,num=5).astype(int)\n",
    "learning_rate = np.logspace(start=-2,stop=0,num=5)\n",
    "lambda_reg = np.logspace(start=0,stop=2,num=3)\n",
    "alpha_reg = np.logspace(start=0,stop=2,num=3)\n",
    "param_grid4 = {'max_depth':max_depth,'n_estimators':n_estimators,'min_child_weight':min_child_weight,\n",
    "               'learning_rate':learning_rate,'lambda':lambda_reg,'alpha':alpha_reg}\n",
    "\n",
    "clf17 = GridSearchCV(estimator=XGBModel2,param_grid=param_grid4,cv=cv,scoring=scoring,return_train_score=True,verbose=3)\n",
    "clf17.fit(df_cleaned3_train, target_upsampled)\n",
    "clf17.score(df_cleaned3_train, target_upsampled)\n",
    "\n",
    "dump(clf17,  '../models/XGB_10cv_gridsearch_biggergrid_upsampled.joblib')\n",
    "\n",
    "clf18 = RandomizedSearchCV(estimator=XGBModel2,param_distributions=param_grid4,n_iter = 100,cv=cv,scoring=scoring,return_train_score=True,verbose=3)\n",
    "clf18.fit(df_cleaned3_train, target_upsampled)\n",
    "clf18.score(df_cleaned3_train, target_upsampled)\n",
    "clf18.best_estimator_\n",
    "\n",
    "dump(clf18,  '../models/XGB_10cv_randomsearch_biggergrid_upsampled.joblib')\n",
    "\n",
    "XGBModel3 = xgb.XGBClassifier(use_label_encoder=False, objective='binary:logistic', eval_metric='auc',\n",
    "                             sampling_method='gradient_based',max_depth=4)\n",
    "\n",
    "n_estimators = np.logspace(start=round(math.log(train_dataset_size/20,2)), stop=round(math.log(train_dataset_size/4,2)),base=2,num=5).astype(int)\n",
    "min_child_weight = np.logspace(start=round(math.log(train_dataset_size/20,2)), stop=round(math.log(train_dataset_size/4),2),base=2,num=5).astype(int)\n",
    "learning_rate = np.logspace(start=-2,stop=0,num=201)\n",
    "param_grid5 = {'n_estimators':n_estimators,'min_child_weight':min_child_weight,\n",
    "               'learning_rate':learning_rate}\n",
    "\n",
    "clf19 = RandomizedSearchCV(estimator=XGBModel3,param_distributions=param_grid5,n_iter = 100,cv=cv,scoring=scoring,return_train_score=True,verbose=3)\n",
    "clf19.fit(df_cleaned3_train, target_upsampled)\n",
    "clf19.score(df_cleaned3_train, target_upsampled)\n",
    "clf19.best_estimator_\n",
    "\n",
    "dump(clf19,  '../models/XGB_10cv_randomsearch_biggergrid_upsampled2.joblib')\n",
    "\n",
    "\n",
    "array_cleaned4_train = scaler.fit_transform(df_cleaned3_train)\n",
    "df_cleaned4_train = pd.DataFrame(array_cleaned4_train,columns=df_col_names)\n",
    "array_cleaned4_test = scaler.transform(df_cleaned3_train) \n",
    "df_cleaned4_test = pd.DataFrame(array_cleaned_test,columns=df_col_names)\n",
    "\n",
    "clf20 = RandomizedSearchCV(estimator=XGBModel3,param_distributions=param_grid5,n_iter = 100,cv=cv,scoring=scoring,return_train_score=True,verbose=3)\n",
    "clf20.fit(df_cleaned4_train, target_upsampled)\n",
    "clf20.score(df_cleaned4_train, target_upsampled)\n",
    "clf20.best_estimator_\n",
    "\n",
    "dump(clf20,  '../models/XGB_10cv_randomsearch_biggergrid_upsampled3.joblib')\n",
    "\n",
    "n_estimators = np.logspace(start=round(math.log(train_dataset_size/20,2)), stop=round(math.log(train_dataset_size/4,2)),base=2,num=5).astype(int)\n",
    "min_child_weight = np.logspace(start=round(math.log(train_dataset_size/20,2)), stop=round(math.log(train_dataset_size/4),2),base=2,num=5).astype(int)\n",
    "learning_rate = np.linspace(start=0.5,stop=1.0,num=201)\n",
    "param_grid6 = {'n_estimators':n_estimators,'min_child_weight':min_child_weight,\n",
    "               'learning_rate':learning_rate}\n",
    "\n",
    "clf21 = RandomizedSearchCV(estimator=XGBModel3,param_distributions=param_grid6,n_iter = 100,cv=cv,scoring=scoring,return_train_score=True,verbose=3)\n",
    "clf21.fit(df_cleaned4_train, target_upsampled)\n",
    "clf21.score(df_cleaned4_train, target_upsampled)\n",
    "clf21.best_estimator_\n",
    "\n",
    "dump(clf21,  '../models/XGB_10cv_randomsearch_biggergrid_upsampled4.joblib')\n",
    "\n",
    "roc_test = clf21.best_estimator_.predict_proba(df_cleaned4_test)[:,1]\n",
    "code = BuildCSVforSubmission(IDlist_test,roc_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
