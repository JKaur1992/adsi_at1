{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539ba4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Wed Feb  9 19:20:51 2022\n",
    "\n",
    "@author: RRZ\n",
    "\"\"\"\n",
    "from joblib import dump\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_raw_train = pd.read_csv('../data/raw/train.csv')\n",
    "df_raw_test = pd.read_csv('../data/raw/test.csv')\n",
    "\n",
    "train_df_size = 0.8\n",
    "rand_state_ind = 42\n",
    "validation_df_size = 0.2\n",
    "\n",
    "df_cleaned_train = df_raw_train.copy()\n",
    "\n",
    "target = df_cleaned_train.pop('TARGET_5Yrs')\n",
    "IDlist_train = df_cleaned_train.pop('Id')\n",
    "df_col_names = df_cleaned_train.columns\n",
    "train_dataset_size = IDlist_train.size\n",
    "\n",
    "scaler = StandardScaler()\n",
    "array_cleaned_train = scaler.fit_transform(df_cleaned_train)\n",
    "df_cleaned2_train = pd.DataFrame(array_cleaned_train,columns=df_col_names)\n",
    "#df_cleaned2_train.insert(loc=0,column='Id',value=IDlist_train)\n",
    "#df_cleaned2_train.set_index(keys='Id',drop=False,verify_integrity=True)\n",
    "\n",
    "df_cleaned_test = df_raw_test.copy()\n",
    "IDlist_test = df_cleaned_test.pop('Id')\n",
    "array_cleaned_test = scaler.transform(df_cleaned_test) \n",
    "df_cleaned2_test = pd.DataFrame(array_cleaned_test,columns=df_col_names)\n",
    "#df_cleaned2_test.insert(loc=0,column='Id',value=IDlist_test)\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "poly.feature_names_in_ = df_col_names\n",
    "array_clean_poly_train = poly.fit_transform(df_cleaned_train)\n",
    "polyFeatureNames = poly.get_feature_names_out()\n",
    "df_cleaned_poly_train = pd.DataFrame(array_clean_poly_train,columns=polyFeatureNames)\n",
    "#df_cleaned_poly_train.insert(loc=0,column='Id',value=IDlist_train)\n",
    "\n",
    "array_clean_poly_test = poly.transform(df_cleaned_test)\n",
    "df_cleaned_poly_test = pd.DataFrame(array_clean_poly_test,columns=polyFeatureNames)\n",
    "#df_cleaned_poly_test.insert(loc=0,column='Id',value=IDlist_test)\n",
    "\n",
    "X_data, X_val, y_data, y_val = train_test_split(df_cleaned2_train, target, train_size=train_df_size, random_state=rand_state_ind, stratify=target)\n",
    "\n",
    "y_train_pos_count = sum(target)\n",
    "y_train_neg_count = target.size - y_train_pos_count\n",
    "\n",
    "y_train_pos_count = sum(y_data)\n",
    "y_train_neg_count = y_data.size - y_train_pos_count\n",
    "\n",
    "y_val_pos_count = sum(y_val)\n",
    "y_val_neg_count = y_val.size - y_val_pos_count\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logRegModel = LogisticRegression(penalty = 'l2')\n",
    "clf = logRegModel.fit(X_data,y_data)\n",
    "y_train_pred = clf.predict(X_data)\n",
    "y_val_pred = clf.predict(X_val)\n",
    "y_test_pred = clf.predict(df_cleaned2_test)\n",
    "\n",
    "roc_train = roc_auc_score(y_data, clf.predict_proba(X_data)[:,1])\n",
    "roc_val = roc_auc_score(y_val, clf.predict_proba(X_val)[:,1])\n",
    "\n",
    "y_train_pred_pos_count = sum(y_train_pred)\n",
    "y_train_pred_neg_count = y_data.size - y_train_pred_pos_count\n",
    "\n",
    "y_val_pred_pos_count = sum(y_val_pred)\n",
    "y_val_pred_neg_count = y_val.size - y_val_pred_pos_count\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "SGDModel = SGDClassifier(loss='modified_huber')\n",
    "clf2 = SGDModel.fit(X_data,y_data)\n",
    "y_train_pred2 = clf2.predict(X_data)\n",
    "y_val_pred2 = clf2.predict(X_val)\n",
    "y_test_pred2 = clf2.predict(df_cleaned2_test)\n",
    "\n",
    "roc_train2 = roc_auc_score(y_data, clf2.predict_proba(X_data)[:,1])\n",
    "roc_val2 = roc_auc_score(y_val, clf2.predict_proba(X_val)[:,1])\n",
    "\n",
    "y_train_pred_pos_count2 = sum(y_train_pred2)\n",
    "y_train_pred_neg_count2 = y_data.size - y_train_pred_pos_count2\n",
    "\n",
    "y_val_pred_pos_count2 = sum(y_val_pred2)\n",
    "y_val_pred_neg_count2 = y_val.size - y_val_pred_pos_count2\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RFModel = RandomForestClassifier()\n",
    "clf3 = RFModel.fit(X_data,y_data)\n",
    "y_train_pred3 = clf3.predict(X_data)\n",
    "y_val_pred3 = clf3.predict(X_val)\n",
    "y_test_pred3 = clf3.predict(df_cleaned2_test)\n",
    "\n",
    "roc_train3 = roc_auc_score(y_data, clf3.predict_proba(X_data)[:,1])\n",
    "roc_val3 = roc_auc_score(y_val, clf3.predict_proba(X_val)[:,1])\n",
    "\n",
    "y_train_pred_pos_count3 = sum(y_train_pred3)\n",
    "y_train_pred_neg_count3 = y_data.size - y_train_pred_pos_count3\n",
    "\n",
    "y_val_pred_pos_count3 = sum(y_val_pred3)\n",
    "y_val_pred_neg_count3 = y_val.size - y_val_pred_pos_count3\n",
    "\n",
    "\n",
    "X_data_poly, X_val_poly, y_data_poly, y_val_poly = train_test_split(df_cleaned_poly_train, target, train_size=train_df_size, random_state=rand_state_ind, stratify=target)\n",
    "\n",
    "clf_poly = logRegModel.fit(X_data_poly,y_data_poly)\n",
    "y_train_poly_pred = clf_poly.predict(X_data_poly)\n",
    "y_val_poly_pred = clf_poly.predict(X_val_poly)\n",
    "y_test_poly_pred = clf_poly.predict(df_cleaned_poly_test)\n",
    "\n",
    "roc_train_poly = roc_auc_score(y_data_poly, clf_poly.predict_proba(X_data_poly)[:,1])\n",
    "roc_val_poly = roc_auc_score(y_val_poly, clf_poly.predict_proba(X_val_poly)[:,1])\n",
    "\n",
    "clf_poly2 = SGDModel.fit(X_data_poly,y_data_poly)\n",
    "y_train_poly_pred2 = clf_poly2.predict(X_data_poly)\n",
    "y_val_poly_pred2 = clf_poly2.predict(X_val_poly)\n",
    "y_test_poly_pred2 = clf_poly2.predict(df_cleaned_poly_test)\n",
    "\n",
    "roc_train_poly2 = roc_auc_score(y_data_poly, clf_poly2.predict_proba(X_data_poly)[:,1])\n",
    "roc_val_poly2 = roc_auc_score(y_val_poly, clf_poly2.predict_proba(X_val_poly)[:,1])\n",
    "\n",
    "clf_poly3 = RFModel.fit(X_data_poly,y_data_poly)\n",
    "y_train_poly_pred3 = clf_poly3.predict(X_data_poly)\n",
    "y_val_poly_pred3 = clf_poly3.predict(X_val_poly)\n",
    "y_test_poly_pred3 = clf_poly3.predict(df_cleaned_poly_test)\n",
    "\n",
    "roc_train_poly3 = roc_auc_score(y_data_poly, clf_poly3.predict_proba(X_data_poly)[:,1])\n",
    "roc_val_poly3 = roc_auc_score(y_val_poly, clf_poly3.predict_proba(X_val_poly)[:,1])\n",
    "\n",
    "\n",
    "def BuildCSVforSubmission(IDlist,PredictionList):\n",
    "    iErrCode = 0\n",
    "    fFileName = 'submission.csv'\n",
    "    if (IDlist.size != 3799) or (PredictionList.size != 3799):\n",
    "        iErrCode = 1\n",
    "    if iErrCode == 0:\n",
    "        if not(isinstance(IDlist, pd.Series)):\n",
    "            list1 = pd.Series(IDlist)\n",
    "        else:\n",
    "            list1 = IDlist.copy()\n",
    "        if not(isinstance(PredictionList, pd.Series)):\n",
    "            list2 = pd.Series(PredictionList)\n",
    "        else:\n",
    "            list2 = IDlist.copy()\n",
    "        #list2.round(2)\n",
    "        #df_out = pd.DataFrame([list1,list2])\n",
    "        df_out = pd.DataFrame({'Id':list1,'TARGET_5Yrs':list2})\n",
    "        df_out.to_csv(path_or_buf = '../data/processed/'+fFileName,index=False)\n",
    "    return iErrCode\n",
    "\n",
    "roc_test = clf.predict_proba(df_cleaned2_test)[:,1]\n",
    "code = BuildCSVforSubmission(IDlist_test,roc_test)\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn import metrics\n",
    "\n",
    "#sorted(metrics.SCORERS.keys())\n",
    "\n",
    "scoring = ['roc_auc']\n",
    "#logreg_scores2 = cross_validate(logRegModel, df_cleaned2_train, target, scoring=scoring, cv=20, return_train_score=True,return_estimator=True)\n",
    "logreg_scores = cross_validate(logRegModel, df_cleaned2_train, target, scoring=scoring, cv=20, return_train_score=True,return_estimator=True)\n",
    "SDG_scores = cross_validate(SGDModel, df_cleaned2_train, target, scoring=scoring, cv=20, return_train_score=True,return_estimator=True)\n",
    "randfor_scores = cross_validate(RFModel, df_cleaned2_train, target, scoring=scoring, cv=20, return_train_score=True,return_estimator=True)\n",
    "\n",
    "best_score = [np.max(logreg_scores.get('test_roc_auc')),np.max(SDG_scores.get('test_roc_auc')),np.max(randfor_scores.get('test_roc_auc'))]\n",
    "best_score_logreg = np.max(logreg_scores.get('test_roc_auc'))\n",
    "logreg_cv_models = logreg_scores.get('estimator')\n",
    "logreg_cv_scores = logreg_scores.get('test_roc_auc')\n",
    "logreg_cv_best_model = np.take(logreg_cv_models,(logreg_cv_scores==best_score_logreg))\n",
    "roc_test_cv = logreg_cv_best_model[0].predict_proba(df_cleaned2_test)[:,1]\n",
    "\n",
    "roc_test = clf.predict_proba(df_cleaned2_test)[:,1]\n",
    "code = BuildCSVforSubmission(IDlist_test,roc_test_cv)\n",
    "\n",
    "# best_score_logreg2 = np.max(logreg_scores2.get('test_roc_auc'))\n",
    "# logreg_cv_models2 = logreg_scores2.get('estimator')\n",
    "# logreg_cv_scores2 = logreg_scores2.get('test_roc_auc')\n",
    "# logreg_cv_best_model2 = np.take(logreg_cv_models2,(logreg_cv_scores2==best_score_logreg2))\n",
    "# roc_test_cv2 = logreg_cv_best_model2[0].predict_proba(df_cleaned2_test)[:,1]\n",
    "\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "NNModel = MLPClassifier()\n",
    "clf4 = NNModel.fit(X_data,y_data)\n",
    "y_train_pred4 = clf4.predict(X_data)\n",
    "y_val_pred4 = clf4.predict(X_val)\n",
    "y_test_pred4 = clf4.predict(df_cleaned2_test)\n",
    "\n",
    "roc_train4 = roc_auc_score(y_data, clf4.predict_proba(X_data)[:,1])\n",
    "roc_val4 = roc_auc_score(y_val, clf4.predict_proba(X_val)[:,1])\n",
    "\n",
    "NN_scores = cross_validate(NNModel, df_cleaned2_train, target, scoring=scoring, cv=20, return_train_score=True,return_estimator=True)\n",
    "best_score_NN = np.max(NN_scores.get('test_roc_auc'))\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "logRegModel = LogisticRegression(penalty = 'l2',max_iter=10000,random_state=42)\n",
    "models = ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "cRegStr = np.logspace(start=1e-3,stop=1e3,num=7)\n",
    "cRegStr = list([1.0,10])\n",
    "class_weight = [None,'balanced']\n",
    "scoring = 'roc_auc'\n",
    "param_grid = {'C':cRegStr,'class_weight':class_weight,'solver':models}\n",
    "#param_grid = {'C':cRegStr,'solver':models}\n",
    "cv = 10\n",
    "\n",
    "clf11 = GridSearchCV(estimator=logRegModel,param_grid=param_grid,cv=cv,scoring=scoring,return_train_score=True,verbose=3)\n",
    "clf11.fit(df_cleaned2_train, target)\n",
    "clf11.best_estimator_\n",
    "clf11.score(df_cleaned2_train, target)\n",
    "clf11.cv_results_.keys()\n",
    "test_grid_1 = clf11.predict_proba(df_cleaned2_test)[:,1]\n",
    "\n",
    "dump(clf11,  '../models/logreg_10cv_gridsearch_basic.joblib')\n",
    "\n",
    "logRegModel = LogisticRegression(penalty = 'l2',max_iter=10000,random_state=42)\n",
    "models = ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "cRegStr = np.logspace(start=-3,stop=3,num=7)\n",
    "#cRegStr = list([1.0,10])\n",
    "class_weight = [None,'balanced']\n",
    "scoring = 'roc_auc'\n",
    "param_grid1a = {'C':cRegStr,'class_weight':class_weight,'solver':models}\n",
    "#param_grid = {'C':cRegStr,'solver':models}\n",
    "cv = 10\n",
    "\n",
    "clf11a = GridSearchCV(estimator=logRegModel,param_grid=param_grid1a,cv=cv,scoring=scoring,return_train_score=True,verbose=3)\n",
    "clf11a.fit(df_cleaned2_train, target)\n",
    "clf11a.best_estimator_\n",
    "clf11a.score(df_cleaned2_train, target)\n",
    "clf11a.cv_results_.keys()\n",
    "test_grid_1a = clf11a.predict_proba(df_cleaned2_test)[:,1]\n",
    "\n",
    "dump(clf11a,  '../models/logreg_10cv_gridsearch_basic2.joblib')\n",
    "\n",
    "\n",
    "RFModel = RandomForestClassifier(random_state=42)\n",
    "n_estimators = np.logspace(start=1, stop=round(math.log(train_dataset_size/2,2)),base=2,num=5).astype(int)\n",
    "max_depth = np.arange(start=2,stop=5)\n",
    "min_samples_split = np.logspace(start=1, stop=round(math.log(train_dataset_size/2),2),base=2,num=5).astype(int)\n",
    "param_grid2 = {'max_depth':max_depth,'n_estimators':n_estimators,'min_samples_split':min_samples_split}\n",
    "\n",
    "clf12 = GridSearchCV(estimator=RFModel,param_grid=param_grid2,cv=cv,scoring=scoring,return_train_score=True,verbose=3)\n",
    "clf12.fit(df_cleaned2_train, target)\n",
    "clf12.best_estimator_\n",
    "clf12.score(df_cleaned2_train, target)\n",
    "clf12.cv_results_.keys()\n",
    "test_grid_2 = clf12.predict_proba(df_cleaned2_test)[:,1]\n",
    "\n",
    "dump(clf12,  '../models/randforest_10cv_gridsearch_basic.joblib')\n",
    "\n",
    "SGDModel = SGDClassifier(max_iter=10000,random_state=42)\n",
    "loss_fn = ['hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron', 'squared_error', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive']\n",
    "alpha = np.linspace(start=-4, stop=3, num=8)\n",
    "l1_ratio = np.linspace(start=0, stop=1, num=6)\n",
    "learning_rate = ['constant', 'optimal', 'invscaling', 'adaptive']\n",
    "param_grid3 = {'loss':loss_fn,'alpha':alpha,'l1_ratio':l1_ratio,'learning_rate':learning_rate}\n",
    "\n",
    "clf13 = GridSearchCV(estimator=SGDModel,param_grid=param_grid3,cv=cv,scoring=scoring,return_train_score=True,verbose=3)\n",
    "clf13.fit(df_cleaned2_train, target)\n",
    "clf13.best_estimator_\n",
    "clf13.score(df_cleaned2_train, target)\n",
    "clf13.cv_results_.keys()\n",
    "test_grid_3 = clf13.predict_proba(df_cleaned2_test)[:,1]\n",
    "\n",
    "dump(clf13,  '../models/SDG_10cv_gridsearch_basic.joblib')\n",
    "\n",
    "from sklearn.utils import resample\n",
    "df_train_posclass = df_raw_train[df_raw_train['TARGET_5Yrs']==1]\n",
    "df_train_negclass = df_raw_train[df_raw_train['TARGET_5Yrs']==0]\n",
    "df_train_negclass_upsampled = resample(df_train_negclass, replace=True, n_samples=y_train_pos_count, random_state=42)\n",
    "\n",
    "df_cleaned3_train = pd.concat([df_train_posclass,df_train_negclass_upsampled])\n",
    "\n",
    "target2 = df_cleaned3_train.pop('TARGET_5Yrs')\n",
    "IDlist_train = df_cleaned3_train.pop('Id')\n",
    "\n",
    "clf14 = GridSearchCV(estimator=logRegModel,param_grid=param_grid1a,cv=cv,scoring=scoring,return_train_score=True,verbose=3)\n",
    "clf14.fit(df_cleaned3_train, target2)\n",
    "clf14.best_estimator_\n",
    "clf14.score(df_cleaned3_train, target2)\n",
    "clf14.cv_results_.keys()\n",
    "test_grid_4 = clf11.predict_proba(df_cleaned2_test)[:,1]\n",
    "\n",
    "dump(clf14,  '../models/logreg_10cv_gridsearch_upsampled.joblib')\n",
    "\n",
    "clf15 = GridSearchCV(estimator=RFModel,param_grid=param_grid2,cv=cv,scoring=scoring,return_train_score=True,verbose=3)\n",
    "clf15.fit(df_cleaned3_train, target2)\n",
    "clf15.best_estimator_\n",
    "clf15.score(df_cleaned3_train, target2)\n",
    "clf15.cv_results_.keys()\n",
    "test_grid_5 = clf11.predict_proba(df_cleaned2_test)[:,1]\n",
    "\n",
    "dump(clf15,  '../models/randforest_10cv_gridsearch_upsampled.joblib')\n",
    "\n",
    "clf16 = GridSearchCV(estimator=SGDModel,param_grid=param_grid3,cv=cv,scoring=scoring,return_train_score=True,verbose=3)\n",
    "clf16.fit(df_cleaned3_train, target2)\n",
    "clf16.best_estimator_\n",
    "clf16.score(df_cleaned3_train, target2)\n",
    "clf16.cv_results_.keys()\n",
    "test_grid_6 = clf11.predict_proba(df_cleaned2_test)[:,1]\n",
    "\n",
    "dump(clf16,  '../models/SDG_10cv_gridsearch_upsampled.joblib')\n",
    "\n",
    "import xgboost as xgb\n",
    "data_dmatrix_train = xgb.DMatrix(data=df_cleaned3_train,label=target)\n",
    "data_dmatrix_test = xgb.DMatrix(data=df_cleaned2_test)\n",
    "\n",
    "XGBModel = xgb.XGBClassifier(use_label_encoder=False, objective='binary:logistic', eval_metric='auc')\n",
    "\n",
    "X_data, X_val, y_data, y_val = train_test_split(df_cleaned3_train, target, train_size=train_df_size, random_state=rand_state_ind, stratify=target)\n",
    "\n",
    "clf6 = XGBModel.fit(X_data, y_data)\n",
    "y_pred = XGBModel.predict_proba(df_cleaned2_test)[:,1]\n",
    "roc_train_XGB = roc_auc_score(y_data, clf6.predict_proba(X_data)[:,1])\n",
    "roc_val_XGB = roc_auc_score(y_val, clf6.predict_proba(X_val)[:,1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
